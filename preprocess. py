import os
import glob
import argparse
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from openvino.runtime import Core
from PIL import Image
import concurrent.futures
import multiprocessing
import time

# --- CONFIG ---
BATCH_SIZE = 32

class PatchDataset(Dataset):
    def __init__(self, file_list, transform=None):
        self.files = file_list
        self.transform = transform
    def __len__(self): return len(self.files)
    def __getitem__(self, idx):
        path = self.files[idx]
        try:
            with Image.open(path) as img:
                return self.transform(img.convert('RGB')), path
        except:
            return torch.zeros(3, 224, 224), path

def process_single_class(args_tuple):
    """
    Worker function that processes ONE entire class.
    We pass arguments as a tuple because ProcessPoolExecutor maps single arguments.
    """
    class_name, data_dir, output_dir, xml_path, bin_path = args_tuple
    
    # 1. Setup paths
    src_folder = os.path.join(data_dir, class_name)
    dst_folder = os.path.join(output_dir, class_name)
    
    # Skip if already done (safety check)
    if os.path.exists(dst_folder) and len(os.listdir(dst_folder)) > 0:
        return f"Skipped {class_name} (Already exists)"
        
    os.makedirs(dst_folder, exist_ok=True)
    
    # 2. Setup OpenVINO INSIDE the process (Crucial!)
    # We force 1 thread per worker so processes don't fight for CPU
    ie = Core()
    model = ie.read_model(model=xml_path, weights=bin_path)
    model.reshape([-1, 3, 224, 224])
    
    # "INFERENCE_NUM_THREADS": 1 is the secret sauce for high throughput
    compiled_model = ie.compile_model(
        model=model, 
        device_name="CPU", 
        config={"INFERENCE_NUM_THREADS": 1, "NUM_STREAMS": 1}
    )
    output_layer = compiled_model.output(0)
    
    # 3. Setup Transform
    tfm = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # 4. Group Files by Prescription
    all_imgs = glob.glob(os.path.join(src_folder, "*.jpg"))
    if not all_imgs: return f"Empty class {class_name}"
    
    rx_map = {}
    for p in all_imgs:
        # Parsing: "Amox_Rx1_patch_0.jpg" -> "Amox_Rx1"
        fname = os.path.basename(p)
        if "_patch_" in fname:
            rx_id = fname.split('_patch_')[0]
        else:
            rx_id = fname.split('.')[0] # Fallback
            
        if rx_id not in rx_map: rx_map[rx_id] = []
        rx_map[rx_id].append(p)
        
    # 5. Inference Loop
    count = 0
    for rx_id, paths in rx_map.items():
        save_path = os.path.join(dst_folder, rx_id + ".pt")
        if os.path.exists(save_path): continue
        
        ds = PatchDataset(paths, transform=tfm)
        # num_workers=0 because we are already in a parallel worker
        loader = DataLoader(ds, batch_size=BATCH_SIZE, num_workers=0) 
        
        features_list = []
        for imgs, _ in loader:
            imgs_np = imgs.numpy()
            res = compiled_model([imgs_np])[output_layer]
            feat = torch.from_numpy(res)
            if len(feat.shape) == 4: feat = feat.view(feat.size(0), -1)
            features_list.append(feat)
            
        if len(features_list) > 0:
            full_tensor = torch.cat(features_list, dim=0)
            torch.save(full_tensor, save_path)
            count += 1
            
    return f"Processed {class_name}: {count} prescriptions"

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data_dir", type=str, required=True) 
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--xml_path", type=str, required=True)
    parser.add_argument("--bin_path", type=str, required=True)
    parser.add_argument("--workers", type=int, default=os.cpu_count(), help="Number of parallel processes")
    args = parser.parse_args()

    # 1. Scan Classes
    print(f"--> Scanning {args.data_dir}...")
    classes = sorted([d for d in os.listdir(args.data_dir) if os.path.isdir(os.path.join(args.data_dir, d))])
    print(f"--> Found {len(classes)} classes.")
    
    # 2. Prepare Task Arguments
    tasks = []
    for cls in classes:
        tasks.append((cls, args.data_dir, args.output_dir, args.xml_path, args.bin_path))

    # 3. Parallel Execution
    print(f"--> Starting Extraction with {args.workers} workers...")
    start_time = time.time()
    
    with concurrent.futures.ProcessPoolExecutor(max_workers=args.workers) as executor:
        # Submit all tasks
        futures = {executor.submit(process_single_class, t): t[0] for t in tasks}
        
        # Monitor Progress
        completed = 0
        total = len(tasks)
        for future in concurrent.futures.as_completed(futures):
            cls_name = futures[future]
            try:
                result = future.result()
                completed += 1
                print(f"[{completed}/{total}] {result}")
            except Exception as e:
                print(f"[ERROR] Class {cls_name} failed: {e}")

    print(f"\n--> Total Time: {(time.time() - start_time)/60:.2f} minutes")

if __name__ == "__main__":
    # Fix for some OS configurations with PyTorch/OpenVINO multiprocessing
    multiprocessing.set_start_method('spawn', force=True)
    main()
